{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "87fd82fb",
   "metadata": {},
   "source": [
    "# IMPORTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b2ac612",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import time\n",
    "import random\n",
    "import getpass\n",
    "from selenium import webdriver\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "from selenium.common.exceptions import NoSuchElementException, StaleElementReferenceException\n",
    "from bs4 import BeautifulSoup\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "084054c8",
   "metadata": {},
   "source": [
    "# SETTING DRIVER"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b76deb6a",
   "metadata": {},
   "source": [
    "```python\n",
    "def driver():\n",
    "    user_agent = 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/114.0.0.0 Safari/537.36'\n",
    "    s = Service(ChromeDriverManager().install())\n",
    "    options = webdriver.ChromeOptions()\n",
    "    options.add_argument('--ignore-certificate-errors')\n",
    "    options.add_argument(f'user-agent={user_agent}')\n",
    "    options.add_argument(\"--window-size=1920,1080\")\n",
    "    return webdriver.Chrome(service=s, options=options)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a56d5773",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The version of chrome cannot be detected. Trying with latest driver version\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<selenium.webdriver.remote.webelement.WebElement (session=\"17eafbd81232a10e0da1597b3ab661f2\", element=\"E0C733E79CCB49FF45F665E48C052578_element_2\")>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "\n",
    "# Configurar el WebDriver para Google Chrome\n",
    "options = webdriver.ChromeOptions()\n",
    "options.binary_location = '/Applications/Google Chrome.app/Contents/MacOS/Google Chrome'\n",
    "wd = webdriver.Chrome(options=options)\n",
    "\n",
    "# Abrir una página web\n",
    "url ='https://www.linkedin.com/jobs/search/?currentJobId=3652284026&geoId=107025191&keywords=data%20analyst&location=Barcelona%2C%20Catalonia%2C%20Spain&refresh=true'\n",
    "\n",
    "wd.get(url)\n",
    "\n",
    "no_of_jobs = int(wd.find_element(By.CSS_SELECTOR, \"h1>span\").get_attribute('innerText'))\n",
    "\n",
    "wd.find_element(By.CSS_SELECTOR, '.jobs-search__results-list')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fa5e071c",
   "metadata": {},
   "outputs": [],
   "source": [
    "wd.get(url)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4144dd0c",
   "metadata": {},
   "source": [
    "# Browse all the jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f8ab77b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "no_of_jobs = int(wd.find_element(By.CSS_SELECTOR, \"h1>span\").get_attribute('innerText'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1db4d66a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<selenium.webdriver.remote.webelement.WebElement (session=\"17eafbd81232a10e0da1597b3ab661f2\", element=\"9B9C0111B96A1FFB8B7A99413CD0530E_element_4\")>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wd.find_element(By.CSS_SELECTOR, '.jobs-search__results-list')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7b479fcd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2000"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "no_of_jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a0180f26",
   "metadata": {},
   "outputs": [],
   "source": [
    "def enconding_url (job_title, location, base_url):\n",
    "    \n",
    "    base_url = \"https://www.linkedin.com/jobs/search\"\n",
    "    \n",
    "    params = {\n",
    "        \"keywords\": job_title,\n",
    "        \"location\": location,\n",
    "    }\n",
    "\n",
    "    encoded_params = \"&\" + \"&\".join([f\"{quote(k)}={quote(v)}\" for k, v in params.items()])\n",
    "    url_with_params = f\"{base_url}{encoded_params}\"\n",
    "\n",
    "    return url_with_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "424e7ee8",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The version of chrome cannot be detected. Trying with latest driver version\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no_of_jobs:  2000\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>company</th>\n",
       "      <th>location</th>\n",
       "      <th>time</th>\n",
       "      <th>url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>HP</td>\n",
       "      <td>Sant Cugat del Vallès</td>\n",
       "      <td>Hace 1 día</td>\n",
       "      <td>https://es.linkedin.com/jobs/view/data-analyst...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Exoticca</td>\n",
       "      <td>Barcelona</td>\n",
       "      <td>Hace 2 meses</td>\n",
       "      <td>https://es.linkedin.com/jobs/view/data-analyst...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Senior Data Analyst</td>\n",
       "      <td>TravelPerk</td>\n",
       "      <td>Barcelona</td>\n",
       "      <td>Hace 2 meses</td>\n",
       "      <td>https://es.linkedin.com/jobs/view/senior-data-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Exoticca</td>\n",
       "      <td>Barcelona</td>\n",
       "      <td>Hace 4 semanas</td>\n",
       "      <td>https://es.linkedin.com/jobs/view/data-analyst...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Danone</td>\n",
       "      <td>Barcelona</td>\n",
       "      <td>Hace 3 meses</td>\n",
       "      <td>https://es.linkedin.com/jobs/view/data-analyst...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Data Engineer</td>\n",
       "      <td>Exoticca</td>\n",
       "      <td>Barcelona</td>\n",
       "      <td>Hace 3 semanas</td>\n",
       "      <td>https://es.linkedin.com/jobs/view/data-enginee...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Sales Intelligence Senior Analyst</td>\n",
       "      <td>MongoDB</td>\n",
       "      <td>Barcelona</td>\n",
       "      <td>Hace 1 día</td>\n",
       "      <td>https://es.linkedin.com/jobs/view/sales-intell...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Data / BI Analyst</td>\n",
       "      <td>AWWG</td>\n",
       "      <td>Barcelona</td>\n",
       "      <td>Hace 17 horas</td>\n",
       "      <td>https://es.linkedin.com/jobs/view/data-bi-anal...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Graduate Program Data Engineer - BCN Global IT...</td>\n",
       "      <td>Nestlé IT North America</td>\n",
       "      <td>Esplugues de Llobregat</td>\n",
       "      <td>Hace 2 días</td>\n",
       "      <td>https://es.linkedin.com/jobs/view/graduate-pro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Analista de Datos Junior (Sector Banca / Power...</td>\n",
       "      <td>Butler Scientifics</td>\n",
       "      <td>Barcelona</td>\n",
       "      <td>Hace 2 horas</td>\n",
       "      <td>https://es.linkedin.com/jobs/view/analista-de-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Paper Street Media</td>\n",
       "      <td>Barcelona</td>\n",
       "      <td>Hace 2 días</td>\n",
       "      <td>https://es.linkedin.com/jobs/view/data-scienti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Data Visualization Analyst</td>\n",
       "      <td>Experfy</td>\n",
       "      <td>Barcelona</td>\n",
       "      <td>Hace 3 meses</td>\n",
       "      <td>https://es.linkedin.com/jobs/view/data-visuali...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Junior Analytics Engineer</td>\n",
       "      <td>Exoticca</td>\n",
       "      <td>Barcelona</td>\n",
       "      <td>Hace 3 semanas</td>\n",
       "      <td>https://es.linkedin.com/jobs/view/junior-analy...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Senior Data Analyst</td>\n",
       "      <td>Zurich Insurance</td>\n",
       "      <td>Barcelona</td>\n",
       "      <td>Hace 52 minutos</td>\n",
       "      <td>https://es.linkedin.com/jobs/view/senior-data-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Pricing Data Scientist</td>\n",
       "      <td>HP</td>\n",
       "      <td>Sant Cugat del Vallès</td>\n",
       "      <td>Hace 1 día</td>\n",
       "      <td>https://es.linkedin.com/jobs/view/pricing-data...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Data Scientist (m/f/d)</td>\n",
       "      <td>ZF Group</td>\n",
       "      <td>Barcelona</td>\n",
       "      <td>Hace 1 día</td>\n",
       "      <td>https://es.linkedin.com/jobs/view/data-scienti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Business Analyst</td>\n",
       "      <td>YABA</td>\n",
       "      <td>Barcelona</td>\n",
       "      <td>Hace 1 día</td>\n",
       "      <td>https://es.linkedin.com/jobs/view/business-ana...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Data Analyst (Operations Team)</td>\n",
       "      <td>Holaluz.com</td>\n",
       "      <td>Barcelona</td>\n",
       "      <td>Hace 2 días</td>\n",
       "      <td>https://es.linkedin.com/jobs/view/data-analyst...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Senior Data Analyst</td>\n",
       "      <td>Caixabank Business Intelligence</td>\n",
       "      <td>Barcelona</td>\n",
       "      <td>Hace 1 día</td>\n",
       "      <td>https://es.linkedin.com/jobs/view/senior-data-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Python Developer with SQL</td>\n",
       "      <td>Avanade</td>\n",
       "      <td>Barcelona</td>\n",
       "      <td>Hace 23 horas</td>\n",
       "      <td>https://es.linkedin.com/jobs/view/python-devel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>AkzoNobel</td>\n",
       "      <td>Barcelona</td>\n",
       "      <td>Hace 2 meses</td>\n",
       "      <td>https://es.linkedin.com/jobs/view/data-scienti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Data Scientist (Andorra)</td>\n",
       "      <td>Gauss &amp; Neumann</td>\n",
       "      <td>Barcelona</td>\n",
       "      <td>Hace 1 mes</td>\n",
       "      <td>https://es.linkedin.com/jobs/view/data-scienti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Business Analyst</td>\n",
       "      <td>Fagron</td>\n",
       "      <td>Barcelona</td>\n",
       "      <td>Hace 2 días</td>\n",
       "      <td>https://es.linkedin.com/jobs/view/business-ana...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                title  \\\n",
       "0                                        Data Analyst   \n",
       "1                                        Data Analyst   \n",
       "2                                 Senior Data Analyst   \n",
       "3                                        Data Analyst   \n",
       "4                                        Data Analyst   \n",
       "5                                       Data Engineer   \n",
       "6                   Sales Intelligence Senior Analyst   \n",
       "7                                   Data / BI Analyst   \n",
       "8   Graduate Program Data Engineer - BCN Global IT...   \n",
       "9   Analista de Datos Junior (Sector Banca / Power...   \n",
       "10                                     Data Scientist   \n",
       "11                         Data Visualization Analyst   \n",
       "12                          Junior Analytics Engineer   \n",
       "13                                Senior Data Analyst   \n",
       "14                             Pricing Data Scientist   \n",
       "15                             Data Scientist (m/f/d)   \n",
       "16                                   Business Analyst   \n",
       "17                     Data Analyst (Operations Team)   \n",
       "18                                Senior Data Analyst   \n",
       "19                          Python Developer with SQL   \n",
       "20                                     Data Scientist   \n",
       "21                           Data Scientist (Andorra)   \n",
       "22                                   Business Analyst   \n",
       "\n",
       "                            company                location             time  \\\n",
       "0                                HP   Sant Cugat del Vallès       Hace 1 día   \n",
       "1                          Exoticca               Barcelona     Hace 2 meses   \n",
       "2                        TravelPerk               Barcelona     Hace 2 meses   \n",
       "3                          Exoticca               Barcelona   Hace 4 semanas   \n",
       "4                            Danone               Barcelona     Hace 3 meses   \n",
       "5                          Exoticca               Barcelona   Hace 3 semanas   \n",
       "6                           MongoDB               Barcelona       Hace 1 día   \n",
       "7                              AWWG               Barcelona    Hace 17 horas   \n",
       "8           Nestlé IT North America  Esplugues de Llobregat      Hace 2 días   \n",
       "9                Butler Scientifics               Barcelona     Hace 2 horas   \n",
       "10               Paper Street Media               Barcelona      Hace 2 días   \n",
       "11                          Experfy               Barcelona     Hace 3 meses   \n",
       "12                         Exoticca               Barcelona   Hace 3 semanas   \n",
       "13                 Zurich Insurance               Barcelona  Hace 52 minutos   \n",
       "14                               HP   Sant Cugat del Vallès       Hace 1 día   \n",
       "15                         ZF Group               Barcelona       Hace 1 día   \n",
       "16                             YABA               Barcelona       Hace 1 día   \n",
       "17                      Holaluz.com               Barcelona      Hace 2 días   \n",
       "18  Caixabank Business Intelligence               Barcelona       Hace 1 día   \n",
       "19                          Avanade               Barcelona    Hace 23 horas   \n",
       "20                        AkzoNobel               Barcelona     Hace 2 meses   \n",
       "21                  Gauss & Neumann               Barcelona       Hace 1 mes   \n",
       "22                           Fagron               Barcelona      Hace 2 días   \n",
       "\n",
       "                                                  url  \n",
       "0   https://es.linkedin.com/jobs/view/data-analyst...  \n",
       "1   https://es.linkedin.com/jobs/view/data-analyst...  \n",
       "2   https://es.linkedin.com/jobs/view/senior-data-...  \n",
       "3   https://es.linkedin.com/jobs/view/data-analyst...  \n",
       "4   https://es.linkedin.com/jobs/view/data-analyst...  \n",
       "5   https://es.linkedin.com/jobs/view/data-enginee...  \n",
       "6   https://es.linkedin.com/jobs/view/sales-intell...  \n",
       "7   https://es.linkedin.com/jobs/view/data-bi-anal...  \n",
       "8   https://es.linkedin.com/jobs/view/graduate-pro...  \n",
       "9   https://es.linkedin.com/jobs/view/analista-de-...  \n",
       "10  https://es.linkedin.com/jobs/view/data-scienti...  \n",
       "11  https://es.linkedin.com/jobs/view/data-visuali...  \n",
       "12  https://es.linkedin.com/jobs/view/junior-analy...  \n",
       "13  https://es.linkedin.com/jobs/view/senior-data-...  \n",
       "14  https://es.linkedin.com/jobs/view/pricing-data...  \n",
       "15  https://es.linkedin.com/jobs/view/data-scienti...  \n",
       "16  https://es.linkedin.com/jobs/view/business-ana...  \n",
       "17  https://es.linkedin.com/jobs/view/data-analyst...  \n",
       "18  https://es.linkedin.com/jobs/view/senior-data-...  \n",
       "19  https://es.linkedin.com/jobs/view/python-devel...  \n",
       "20  https://es.linkedin.com/jobs/view/data-scienti...  \n",
       "21  https://es.linkedin.com/jobs/view/data-scienti...  \n",
       "22  https://es.linkedin.com/jobs/view/business-ana...  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "import os\n",
    "import pandas as pd\n",
    "import time\n",
    "import random\n",
    "import getpass\n",
    "from bs4 import BeautifulSoup\n",
    "from tqdm import tqdm\n",
    "from urllib.parse import urlencode\n",
    "from urllib.parse import quote\n",
    "\n",
    "from selenium import webdriver\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "from selenium.common.exceptions import NoSuchElementException, StaleElementReferenceException\n",
    "\n",
    "\n",
    "def scraping_cards_on_the_left(job_title=\"data\", location=\"Barcelona, Catalonia, Spain\"):\n",
    "    options = webdriver.ChromeOptions()\n",
    "    options.binary_location = '/Applications/Google Chrome.app/Contents/MacOS/Google Chrome'\n",
    "    wd = webdriver.Chrome(options=options)\n",
    "    \n",
    "    url = 'https://www.linkedin.com/jobs/search/?currentJobId=3652284026&geoId=107025191&keywords=data%20analyst&location=Barcelona%2C%20Catalonia%2C%20Spain&refresh=true'\n",
    "    \n",
    "    wd.get(url)\n",
    "    no_of_jobs = int(wd.find_element(By.CSS_SELECTOR, \"h1>span\").get_attribute('innerText'))\n",
    "    print(\"no_of_jobs: \", no_of_jobs)\n",
    "    wd.find_element(By.CSS_SELECTOR, '.jobs-search__results-list')\n",
    "    \n",
    "    jobsitos = []\n",
    "    els_jobs = []\n",
    "    i = 1\n",
    "\n",
    "    previous_page_content = \"\"  # Variable para almacenar el contenido de la página anterior\n",
    "\n",
    "    while i <= int(no_of_jobs/25) + 1:\n",
    "        wd.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "        i = i + 1\n",
    "        try:\n",
    "            job_lists = wd.find_element(By.CSS_SELECTOR, '.jobs-search__results-list')\n",
    "            listita = job_lists.get_attribute('outerHTML')\n",
    "            soup = BeautifulSoup(listita, \"html.parser\")\n",
    "            soup_2 = soup.find_all(\"ul\", {\"class\": \"jobs-search__results-list\"})\n",
    "\n",
    "            # 1. EXTRAER JOB A JOB\n",
    "            for pagina in soup_2:\n",
    "                jobsitos.append(pagina)\n",
    "\n",
    "            # 2. EXTRAER LA INFO DE CADA JOB\n",
    "            for job in jobsitos:\n",
    "                job_list = job.find_all(\"li\")\n",
    "\n",
    "                for the_one_job in job_list:\n",
    "                    url = the_one_job.find_all(\"a\")[0].get(\"href\")\n",
    "                    title = the_one_job.find_all(\"span\", {\"class\":\"sr-only\"})[0].text.strip()\n",
    "                    location = the_one_job.find_all(\"span\", {\"class\": \"job-search-card__location\" })[0].text.strip()\n",
    "                    company = the_one_job.find_all(\"h4\")[0].find(\"a\").text.strip()\n",
    "                    the_time = the_one_job.find_all(\"time\")[0].text.strip()\n",
    "\n",
    "                    dict_ = {\n",
    "                        \"title\": title,\n",
    "                        \"company\": company,\n",
    "                        \"location\": location,\n",
    "                        \"time\": the_time,\n",
    "                        \"url\": url,\n",
    "                    }\n",
    "\n",
    "                    if dict_ not in els_jobs:\n",
    "                        els_jobs.append(dict_)\n",
    "\n",
    "            time.sleep(5)\n",
    "\n",
    "            # Verificar si el botón \"Ver más empleos\" está presente y hacer clic en él\n",
    "            show_more_button = wd.find_elements(By.CSS_SELECTOR, '.infinite-scroller__show-more-button')\n",
    "            if show_more_button:\n",
    "                show_more_button[0].click()\n",
    "                time.sleep(5)\n",
    "                \n",
    "                # Verificar si el contenido de la página ha cambiado después de hacer clic\n",
    "                current_page_content = wd.page_source\n",
    "\n",
    "                if current_page_content == previous_page_content:\n",
    "                    break  # Salir del bucle si no hay más trabajos disponibles\n",
    "\n",
    "                previous_page_content = current_page_content\n",
    "\n",
    "            else:\n",
    "                break  # Salir del bucle si el botón no está presente\n",
    "\n",
    "        except:\n",
    "            pass\n",
    "        time.sleep(5)\n",
    "\n",
    "    os.system(\"say -v Monica don escreipin\")\n",
    "    return pd.DataFrame(els_jobs)\n",
    "\n",
    "df_2 = scraping_cards_on_the_left()\n",
    "df_2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d6c8b51a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2.to_csv('ultimo_ultimo.csv', index= False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6a184bf",
   "metadata": {},
   "source": [
    "df_2.to_csv('ultimo_funcion_1.csv', index=False)\n",
    "df_last = pd.read_csv('ultimo_funcion_1.csv')\n",
    "df_primerexito = pd.read_csv('primer_exito_bro_to_wapo.csv')\n",
    "df_medio = pd.read_csv('all_data_analysts_jobs175.csv')\n",
    "df_primero = pd.read_csv('all_data_analysts_jobs.csv')\n",
    "df_combined = pd.concat([df_last, df_primero, df_medio, df_primerexito]).drop_duplicates()\n",
    "df_combined.to_csv('first_function_datajobs.csv', index=False)\n",
    "df_combined_2 = df_combined.reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dfd2eba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_last = pd.read_csv('ultimo_funcion_1.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c92833ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_primero = pd.read_csv('all_data_analysts_jobs.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b8b5892c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_medio = pd.read_csv('all_data_analysts_jobs175.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "11630a9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_primerexito = pd.read_csv('primer_exito_bro_to_wapo.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "def2e95a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_combined = pd.concat([df_last, df_primero, df_medio, df_primerexito, df_2]).drop_duplicates()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "54ce6a7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final_url = pd.read_csv('csv_urls.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "df6acd16",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_combined_2.to_csv('csv_urls_2.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c09204fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://es.linkedin.com/jobs/view/data-analyst-at-exoticca-3622172076?refId=jWf2Fweu6LwaRUAHa5CNVQ%3D%3D&trackingId=vzc7hXRuY8DFO0xPl1w3VA%3D%3D&position=1&pageNum=0&trk=public_jobs_jserp-result_search-card'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_final_url.url[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dc36fdf",
   "metadata": {},
   "source": [
    "# Scrapear detalles del job"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec6c5e31",
   "metadata": {},
   "source": [
    "options = webdriver.ChromeOptions()\n",
    "options.binary_location = '/Applications/Google Chrome.app/Contents/MacOS/Google Chrome'\n",
    "wd = webdriver.Chrome(options=options)\n",
    "url_job = \"https://es.linkedin.com/jobs/view/data-analyst-at-coniq-3652827423?refId=LmHLqc2XCC2YJGeJ%2BOJlfw%3D%3D&trackingId=CtHhJ%2Fe3ZQTxs8KZpryElw%3D%3D&position=1&pageNum=0&trk=public_jobs_jserp-result_search-card\"\n",
    "wd.get(url_job)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "577e5211",
   "metadata": {},
   "source": [
    "#Description’: jd\n",
    "#Seniority\n",
    "#Type’: emp_type,\n",
    "#Function’: job_func,"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50b5336c",
   "metadata": {},
   "source": [
    "def logging_in (url):\n",
    "    \n",
    "    # 1. Initializing driver\n",
    "    options = webdriver.ChromeOptions()\n",
    "    options.binary_location = '/Applications/Google Chrome.app/Contents/MacOS/Google Chrome'\n",
    "    wd = webdriver.Chrome(options=options)\n",
    "    wd.get(url)\n",
    "    \n",
    "    # 2. Try to log-in\n",
    "    \n",
    "    try:\n",
    "        time.sleep(5)\n",
    "        driver.find_element(By.XPATH,'/html/body/header/nav/div/a[2]').click()\n",
    "        mail = 'cocazapata.21@gmail.com'\n",
    "        pw = 'fcbarcelona21'\n",
    "        time.sleep(3)\n",
    "        print(\"Logging in\")\n",
    "\n",
    "        username = wait.until(EC.visibility_of_element_located((By.ID, 'username'))).send_keys(mail)\n",
    "        password = wait.until(EC.visibility_of_element_located((By.ID, 'password'))).send_keys(pw)\n",
    "        password.send_keys(Keys.RETURN)\n",
    "        time.sleep(2)\n",
    "        return wd.page_source\n",
    "        \n",
    "    # 3. Otherwise: try to just get the content\n",
    "        \n",
    "    except:\n",
    "        print(\"Not logging in\")\n",
    "        time.sleep(2)\n",
    "        return wd.page_source"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a86cd438",
   "metadata": {},
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "\n",
    "def info_un_job(url):\n",
    "    \n",
    "    response = logging_in (url)\n",
    "    soup = BeautifulSoup(response, 'html.parser')\n",
    "    descripcion = soup.find('div', {\"class\":'description__text description__text--rich'}).get_text(strip=True)\n",
    "    nivel_antiguedad = soup.find('span', {\"class\":\"description__job-criteria-text description__job-criteria-text--criteria\"}).get_text(strip=True)\n",
    "    sectores = soup.find('span', {\"class\":\"description__job-criteria-text description__job-criteria-text--criteria\"})\n",
    "    \n",
    "    dict_ = {\n",
    "        \"description\": descripcion,\n",
    "        \"nivel_antiguedad\": nivel_antiguedad,\n",
    "        \"sectores\": sectores\n",
    "    }\n",
    "    \n",
    "    return dict_\n",
    "    \n",
    "\n",
    "url = 'https://es.linkedin.com/jobs/view/data-analyst-at-coniq-3652827423?refId=LmHLqc2XCC2YJGeJ%2BOJlfw%3D%3D&trackingId=CtHhJ%2Fe3ZQTxs8KZpryElw%3D%3D&position=1&pageNum=0&trk=public_jobs_jserp-result_search-card'\n",
    "\n",
    "resultado = info_un_job(url)\n",
    "resultado\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9c41a3d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad1fd35e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aca4174",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "984eea2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The version of chrome cannot be detected. Trying with latest driver version\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging in\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'get_text'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/q7/v3v0dp3x75b1z141v2hlcr3c0000gn/T/ipykernel_31766/100595955.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m \u001b[0murl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'https://es.linkedin.com/jobs/view/data-analyst-at-exoticca-3622172076?refId=jWf2Fweu6LwaRUAHa5CNVQ%3D%3D&trackingId=vzc7hXRuY8DFO0xPl1w3VA%3D%3D&position=1&pageNum=0&trk=public_jobs_jserp-result_search-card'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 104\u001b[0;31m \u001b[0mresultado\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minfo_un_job\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    105\u001b[0m \u001b[0mdf_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mresultado\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m \u001b[0mdf_test\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/q7/v3v0dp3x75b1z141v2hlcr3c0000gn/T/ipykernel_31766/100595955.py\u001b[0m in \u001b[0;36minfo_un_job\u001b[0;34m(url)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0msoup\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBeautifulSoup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'html.parser'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m     \u001b[0mcompany\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msoup\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'span'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"class\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\"jobs-unified-top-card__company-name\"\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m     \u001b[0mposition\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msoup\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'h1'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"class\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\"t-24 t-bold jobs-unified-top-card__job-title\"\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m     \u001b[0mlocation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msoup\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'span'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"class\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\"jobs-unified-top-card__bullet\"\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'get_text'"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from bs4 import BeautifulSoup\n",
    "from datetime import datetime\n",
    "import os\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "import os\n",
    "import pandas as pd\n",
    "import time\n",
    "import random\n",
    "import getpass\n",
    "from bs4 import BeautifulSoup\n",
    "from tqdm import tqdm\n",
    "from urllib.parse import urlencode\n",
    "from urllib.parse import quote\n",
    "\n",
    "from selenium import webdriver\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "from selenium.common.exceptions import NoSuchElementException, StaleElementReferenceException\n",
    "\n",
    "\n",
    "\n",
    "def logging_in(url):\n",
    "    options = webdriver.ChromeOptions()\n",
    "    options.binary_location = '/Applications/Google Chrome.app/Contents/MacOS/Google Chrome'\n",
    "    wd = webdriver.Chrome(options=options)\n",
    "    wd.get(url)\n",
    "\n",
    "    try:\n",
    "        time.sleep(3)\n",
    "        wd.find_element(By.XPATH, '/html/body/header/nav/div/a[2]').click()\n",
    "        mail = 'cocazapata.21@gmail.com'\n",
    "        pw = 'fcbarcelona21'\n",
    "        time.sleep(3)\n",
    "        print(\"Logging in\")\n",
    "\n",
    "        username = wd.find_element(By.ID, 'username')\n",
    "        username.send_keys(mail)\n",
    "        password = wd.find_element(By.ID, 'password')\n",
    "        password.send_keys(pw)\n",
    "        password.send_keys(Keys.RETURN)\n",
    "        time.sleep(5)\n",
    "        return wd\n",
    "    except:\n",
    "        print(\"Not logging in\")\n",
    "        time.sleep(4)\n",
    "        return wd\n",
    "\n",
    "\n",
    "def info_un_job(url):\n",
    "    wd = logging_in(url)\n",
    "    \n",
    "    response = wd.page_source\n",
    "    soup = BeautifulSoup(response, 'html.parser')\n",
    "    \n",
    "    company = soup.find('span', {\"class\":\"jobs-unified-top-card__company-name\"}).get_text(strip=True)\n",
    "    position = soup.find('h1', {\"class\":\"t-24 t-bold jobs-unified-top-card__job-title\"}).get_text(strip=True)\n",
    "    location = soup.find('span', {\"class\":\"jobs-unified-top-card__bullet\"}).get_text(strip=True)\n",
    "    workplace = soup.find('span', {\"class\":\"jobs-unified-top-card__workplace-type\"}).get_text(strip=True)\n",
    "    type_and_level = soup.find(\"li\", {\"class\": \"jobs-unified-top-card__job-insight\"}).find(\"span\").text.strip()\n",
    "    description = soup.find('div', {\"class\": 'jobs-box__html-content jobs-description-content__text t-14 t-normal jobs-description-content__text--stretch'}).get_text(strip=True)\n",
    "    today = datetime.today().strftime('%d-%m-%Y')\n",
    "    link_text = soup.find('a', class_='app-aware-link').text.strip()\n",
    "    #workers = soup.find(\"li\", {\"class\": \"jobs-unified-top-card__job-insight\"}).find(\"span\").text.strip()\n",
    "    #num_alumnis = link_text.split()[0]\n",
    "    applicants = soup.find('span', class_='jobs-unified-top-card__applicant-count')\n",
    "    applicants = applicants.text.strip() if applicants else None\n",
    "    \n",
    "    dict_2 = {\n",
    "        \"company\" : company,\n",
    "        \"position\": position,\n",
    "        \"location\": location,\n",
    "        \"workplace\" : workplace,\n",
    "        \"type_and_level\": type_and_level,\n",
    "        \"description\": description,\n",
    "        \"today\": today,\n",
    "        \"url\": url,\n",
    "        \"applicants\": applicants,\n",
    "        #\"workers\": workers,\n",
    "         #\"num_alumnis\": num_alumnis,\n",
    "        \n",
    "    }\n",
    "    \n",
    "    os.system(\"say -v Monica don escreipin\")\n",
    "\n",
    "    return dict_2\n",
    "\n",
    "url = 'https://es.linkedin.com/jobs/view/data-analyst-at-exoticca-3622172076?refId=jWf2Fweu6LwaRUAHa5CNVQ%3D%3D&trackingId=vzc7hXRuY8DFO0xPl1w3VA%3D%3D&position=1&pageNum=0&trk=public_jobs_jserp-result_search-card'\n",
    "resultado = info_un_job(url)\n",
    "df_test = pd.DataFrame([resultado])\n",
    "df_test\n",
    "\n",
    "df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beb59394",
   "metadata": {},
   "outputs": [],
   "source": [
    "resultado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "390dd127",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cf1b43b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4efee4ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "job_data = pd.DataFrame({\n",
    "    'ID': job_id,\n",
    "    'Date': date,\n",
    "    'Company': company_name,\n",
    "    'Title': job_title,\n",
    "    'Location': location,\n",
    "    'Description': jd,\n",
    "    'Level': seniority,\n",
    "    'Type': emp_type,\n",
    "    'Function': job_func,\n",
    "    'Industry': industries,\n",
    "    'Link': job_link\n",
    "})\n",
    "\n",
    "# Limpiar la columna \"Description\"\n",
    "job_data['Description'] = job_data['Description'].str.replace('\\n', ' ')\n",
    "\n",
    "job_data.to_excel('LinkedIn Job Data_Data Scientist.xlsx', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "371bf394",
   "metadata": {},
   "outputs": [],
   "source": [
    "job_data = pd.DataFrame({‘ID’: job_id,\n",
    "‘Date’: date,\n",
    "‘Company’: company_name,\n",
    "‘Title’: job_title,\n",
    "‘Location’: location,\n",
    "'Description’: jd,\n",
    "‘Level’: seniority,\n",
    "‘Type’: emp_type,\n",
    "‘Function’: job_func,\n",
    "‘Industry’: industries,\n",
    "‘Link’: job_link\n",
    "})\n",
    "# cleaning description column\n",
    "job_data[‘Description’] = job_data[‘Description’].str.replace(‘\\n’,’ ‘)\n",
    "job_data.to_excel('LinkedIn Job Data_Data Scientist.xlsx', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04fff95f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
