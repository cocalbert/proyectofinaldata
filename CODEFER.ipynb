{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d7ebd578",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import time\n",
    "import random\n",
    "import getpass\n",
    "from selenium import webdriver\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "from selenium.common.exceptions import NoSuchElementException, StaleElementReferenceException\n",
    "from bs4 import BeautifulSoup\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "084054c8",
   "metadata": {},
   "source": [
    "# SETTING DRIVER"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b76deb6a",
   "metadata": {},
   "source": [
    "```python\n",
    "def driver():\n",
    "    user_agent = 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/114.0.0.0 Safari/537.36'\n",
    "    s = Service(ChromeDriverManager().install())\n",
    "    options = webdriver.ChromeOptions()\n",
    "    options.add_argument('--ignore-certificate-errors')\n",
    "    options.add_argument(f'user-agent={user_agent}')\n",
    "    options.add_argument(\"--window-size=1920,1080\")\n",
    "    return webdriver.Chrome(service=s, options=options)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a56d5773",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The version of chrome cannot be detected. Trying with latest driver version\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<selenium.webdriver.remote.webelement.WebElement (session=\"3782a1acb2463b0389e9532aae0a54d4\", element=\"14E07322312F8D41E926B7F64EA58D9B_element_16\")>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "\n",
    "# Configurar el WebDriver para Google Chrome\n",
    "options = webdriver.ChromeOptions()\n",
    "options.binary_location = '/Applications/Google Chrome.app/Contents/MacOS/Google Chrome'\n",
    "wd = webdriver.Chrome(options=options)\n",
    "\n",
    "# Abrir una página web\n",
    "url ='https://www.linkedin.com/jobs/search/?currentJobId=3622216694&geoId=107025191&keywords=data&location=Barcelona%2C%20Catalonia%2C%20Spain&refresh=true'\n",
    "\n",
    "wd.get(url)\n",
    "\n",
    "no_of_jobs = int(wd.find_element(By.CSS_SELECTOR, \"h1>span\").get_attribute('innerText'))\n",
    "\n",
    "wd.find_element(By.CSS_SELECTOR, '.jobs-search__results-list')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fa5e071c",
   "metadata": {},
   "outputs": [],
   "source": [
    "wd.get(url)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4144dd0c",
   "metadata": {},
   "source": [
    "# Browse all the jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f8ab77b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "no_of_jobs = int(wd.find_element(By.CSS_SELECTOR, \"h1>span\").get_attribute('innerText'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1db4d66a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<selenium.webdriver.remote.webelement.WebElement (session=\"3782a1acb2463b0389e9532aae0a54d4\", element=\"642AF33DD49F49506ABB2AAA3FDE2F08_element_33\")>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wd.find_element(By.CSS_SELECTOR, '.jobs-search__results-list')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7b479fcd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3000"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "no_of_jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "a0180f26",
   "metadata": {},
   "outputs": [],
   "source": [
    "def enconding_url (job_title, location, base_url):\n",
    "    \n",
    "    base_url = \"https://www.linkedin.com/jobs/search\"\n",
    "    \n",
    "    params = {\n",
    "        \"keywords\": job_title,\n",
    "        \"location\": location,\n",
    "    }\n",
    "\n",
    "    encoded_params = \"&\" + \"&\".join([f\"{quote(k)}={quote(v)}\" for k, v in params.items()])\n",
    "    url_with_params = f\"{base_url}{encoded_params}\"\n",
    "\n",
    "    return url_with_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "424e7ee8",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The version of chrome cannot be detected. Trying with latest driver version\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no_of_jobs:  3000\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>company</th>\n",
       "      <th>location</th>\n",
       "      <th>time</th>\n",
       "      <th>url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Tècnic/a Suport Direcció Ref. 107-2023</td>\n",
       "      <td>Hospital Sant Joan de Déu Barcelona</td>\n",
       "      <td>Esplugues de Llobregat</td>\n",
       "      <td>Hace 1 semana</td>\n",
       "      <td>https://es.linkedin.com/jobs/view/t%C3%A8cnic-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Hubtype</td>\n",
       "      <td>Barcelona</td>\n",
       "      <td>Hace 1 mes</td>\n",
       "      <td>https://es.linkedin.com/jobs/view/data-scienti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Visualization Analyst</td>\n",
       "      <td>Experfy</td>\n",
       "      <td>Barcelona</td>\n",
       "      <td>Hace 3 meses</td>\n",
       "      <td>https://es.linkedin.com/jobs/view/data-visuali...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Coniq</td>\n",
       "      <td>Barcelona</td>\n",
       "      <td>Hace 1 mes</td>\n",
       "      <td>https://es.linkedin.com/jobs/view/data-analyst...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Research Assistant in the Department of Economics</td>\n",
       "      <td>IESE Business School - University of Navarra</td>\n",
       "      <td>Barcelona</td>\n",
       "      <td>Hace 1 semana</td>\n",
       "      <td>https://es.linkedin.com/jobs/view/research-ass...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Exoticca</td>\n",
       "      <td>Barcelona</td>\n",
       "      <td>Hace 2 meses</td>\n",
       "      <td>https://es.linkedin.com/jobs/view/data-analyst...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Graduado/a para dar apoyo en un proyecto de in...</td>\n",
       "      <td>Fundació de Recerca Sant Joan de Déu</td>\n",
       "      <td>Sant Boi de Llobregat</td>\n",
       "      <td>Hace 2 semanas</td>\n",
       "      <td>https://es.linkedin.com/jobs/view/graduado-a-p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Research Assistant in Data Science/Management/...</td>\n",
       "      <td>IESE Business School - University of Navarra</td>\n",
       "      <td>Barcelona</td>\n",
       "      <td>Hace 1 semana</td>\n",
       "      <td>https://es.linkedin.com/jobs/view/research-ass...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Business Analytics (Flights)</td>\n",
       "      <td>Exoticca</td>\n",
       "      <td>Barcelona</td>\n",
       "      <td>Hace 2 meses</td>\n",
       "      <td>https://es.linkedin.com/jobs/view/business-ana...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Paper Street Media</td>\n",
       "      <td>Barcelona</td>\n",
       "      <td>Hace 11 horas</td>\n",
       "      <td>https://es.linkedin.com/jobs/view/data-scienti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Paper Street Media</td>\n",
       "      <td>Barcelona</td>\n",
       "      <td>Hace 1 mes</td>\n",
       "      <td>https://es.linkedin.com/jobs/view/data-scienti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Data Analyst - QA Tester</td>\n",
       "      <td>Experfy</td>\n",
       "      <td>Barcelona</td>\n",
       "      <td>Hace 1 mes</td>\n",
       "      <td>https://es.linkedin.com/jobs/view/data-analyst...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Junior Analytics Engineer</td>\n",
       "      <td>Exoticca</td>\n",
       "      <td>Barcelona</td>\n",
       "      <td>Hace 3 semanas</td>\n",
       "      <td>https://es.linkedin.com/jobs/view/junior-analy...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Birchman Group Spain</td>\n",
       "      <td>Barcelona</td>\n",
       "      <td>Hace 2 meses</td>\n",
       "      <td>https://es.linkedin.com/jobs/view/data-analyst...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Industrial Affairs (IA) Data Scientist</td>\n",
       "      <td>Experfy</td>\n",
       "      <td>Barcelona</td>\n",
       "      <td>Hace 3 meses</td>\n",
       "      <td>https://es.linkedin.com/jobs/view/industrial-a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Research Assistant in Economics/Marketing/Finance</td>\n",
       "      <td>IESE Business School - University of Navarra</td>\n",
       "      <td>Barcelona</td>\n",
       "      <td>Hace 4 días</td>\n",
       "      <td>https://es.linkedin.com/jobs/view/research-ass...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Smadex</td>\n",
       "      <td>Barcelona</td>\n",
       "      <td>Hace 1 mes</td>\n",
       "      <td>https://es.linkedin.com/jobs/view/data-scienti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>DATA SCIENTIST</td>\n",
       "      <td>MANGO</td>\n",
       "      <td>Barcelona</td>\n",
       "      <td>Hace 7 horas</td>\n",
       "      <td>https://es.linkedin.com/jobs/view/data-scienti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Full-time research assistant position Prof. Vi...</td>\n",
       "      <td>IESE Business School - University of Navarra</td>\n",
       "      <td>Barcelona</td>\n",
       "      <td>Hace 1 mes</td>\n",
       "      <td>https://es.linkedin.com/jobs/view/full-time-re...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Junior Product Analyst (Full remote within Spain)</td>\n",
       "      <td>Leadtech Group</td>\n",
       "      <td>Barcelona</td>\n",
       "      <td>Hace 3 meses</td>\n",
       "      <td>https://es.linkedin.com/jobs/view/junior-produ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Data Scientist Junior</td>\n",
       "      <td>Between Technology</td>\n",
       "      <td>Palau-solità i Plegamans</td>\n",
       "      <td>Hace 2 meses</td>\n",
       "      <td>https://es.linkedin.com/jobs/view/data-scienti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Winning</td>\n",
       "      <td>Barcelona</td>\n",
       "      <td>Hace 1 mes</td>\n",
       "      <td>https://es.linkedin.com/jobs/view/data-scienti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Eurecat - Centro Tecnológico de Catalunya</td>\n",
       "      <td>Barcelona</td>\n",
       "      <td>Hace 1 mes</td>\n",
       "      <td>https://es.linkedin.com/jobs/view/data-scienti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Data Scientist - Bioinformática Remoto</td>\n",
       "      <td>Page Personnel</td>\n",
       "      <td>Barcelona</td>\n",
       "      <td>Hace 1 día</td>\n",
       "      <td>https://es.linkedin.com/jobs/view/data-scienti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Data Scientist - Bioinformática - 100% remoto</td>\n",
       "      <td>Page Personnel</td>\n",
       "      <td>Barcelona y alrededores</td>\n",
       "      <td>Hace 4 días</td>\n",
       "      <td>https://es.linkedin.com/jobs/view/data-scienti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Research Assistant Prof. Hester Zhang</td>\n",
       "      <td>IESE Business School - University of Navarra</td>\n",
       "      <td>Barcelona</td>\n",
       "      <td>Hace 2 semanas</td>\n",
       "      <td>https://es.linkedin.com/jobs/view/research-ass...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>PERSONAL AMB TITULACIÓ SUPERIOR EN PSICOLOGIA ...</td>\n",
       "      <td>Fundació de Recerca Sant Joan de Déu</td>\n",
       "      <td>Sant Boi de Llobregat</td>\n",
       "      <td>Hace 3 semanas</td>\n",
       "      <td>https://es.linkedin.com/jobs/view/personal-amb...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Becario/a Analista de Datos</td>\n",
       "      <td>Grupo Planeta</td>\n",
       "      <td>Barcelona</td>\n",
       "      <td>Hace 2 semanas</td>\n",
       "      <td>https://es.linkedin.com/jobs/view/becario-a-an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>BECARIO/A DATA ANALYST CLIENTE</td>\n",
       "      <td>MANGO</td>\n",
       "      <td>Barcelona</td>\n",
       "      <td>Hace 1 mes</td>\n",
       "      <td>https://es.linkedin.com/jobs/view/becario-a-da...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Principal Data Scientist</td>\n",
       "      <td>Experfy</td>\n",
       "      <td>Barcelona</td>\n",
       "      <td>Hace 3 meses</td>\n",
       "      <td>https://es.linkedin.com/jobs/view/principal-da...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Data Science - 100% remoto (based in Spain)</td>\n",
       "      <td>Michael Page</td>\n",
       "      <td>Barcelona</td>\n",
       "      <td>Hace 5 días</td>\n",
       "      <td>https://es.linkedin.com/jobs/view/data-science...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Business Analyst</td>\n",
       "      <td>Paper Street Media</td>\n",
       "      <td>Barcelona</td>\n",
       "      <td>Hace 11 horas</td>\n",
       "      <td>https://es.linkedin.com/jobs/view/business-ana...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>Data Analyst Internship</td>\n",
       "      <td>HP</td>\n",
       "      <td>Sant Cugat del Vallès</td>\n",
       "      <td>Hace 1 mes</td>\n",
       "      <td>https://es.linkedin.com/jobs/view/data-analyst...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>Data Management Officer</td>\n",
       "      <td>HOLA CONSULTORES SL</td>\n",
       "      <td>Barcelona</td>\n",
       "      <td>Hace 3 días</td>\n",
       "      <td>https://es.linkedin.com/jobs/view/data-managem...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Page Personnel</td>\n",
       "      <td>Barcelona</td>\n",
       "      <td>Hace 4 días</td>\n",
       "      <td>https://es.linkedin.com/jobs/view/data-scienti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>REPORTING &amp; CONTROLLING</td>\n",
       "      <td>MANGO</td>\n",
       "      <td>Barcelona</td>\n",
       "      <td>Hace 3 semanas</td>\n",
       "      <td>https://es.linkedin.com/jobs/view/reporting-co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>Business Analyst</td>\n",
       "      <td>Paper Street Media</td>\n",
       "      <td>Barcelona</td>\n",
       "      <td>Hace 1 mes</td>\n",
       "      <td>https://es.linkedin.com/jobs/view/business-ana...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>Python Developer Jr. (for ML team)</td>\n",
       "      <td>Smadex</td>\n",
       "      <td>Barcelona</td>\n",
       "      <td>Hace 1 mes</td>\n",
       "      <td>https://es.linkedin.com/jobs/view/python-devel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>DATA SCIENTIST</td>\n",
       "      <td>MANGO</td>\n",
       "      <td>Barcelona</td>\n",
       "      <td>Hace 1 mes</td>\n",
       "      <td>https://es.linkedin.com/jobs/view/data-scienti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>Junior Sales Development Representative (SDR)</td>\n",
       "      <td>Hubtype</td>\n",
       "      <td>Barcelona</td>\n",
       "      <td>Hace 1 semana</td>\n",
       "      <td>https://es.linkedin.com/jobs/view/junior-sales...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>Investigador/a Inteligencia Artificial Optimiz...</td>\n",
       "      <td>Eurecat - Centro Tecnológico de Catalunya</td>\n",
       "      <td>Barcelona</td>\n",
       "      <td>Hace 2 meses</td>\n",
       "      <td>https://es.linkedin.com/jobs/view/investigador...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>Lead Data Scientist</td>\n",
       "      <td>Experfy</td>\n",
       "      <td>Barcelona</td>\n",
       "      <td>Hace 3 meses</td>\n",
       "      <td>https://es.linkedin.com/jobs/view/lead-data-sc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>Market Intelligence Intern</td>\n",
       "      <td>Mars</td>\n",
       "      <td>Barcelona</td>\n",
       "      <td>Hace 3 horas</td>\n",
       "      <td>https://es.linkedin.com/jobs/view/market-intel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>Chief Operating Officer</td>\n",
       "      <td>ABCDx SA</td>\n",
       "      <td>Barcelona</td>\n",
       "      <td>Hace 1 mes</td>\n",
       "      <td>https://es.linkedin.com/jobs/view/chief-operat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>Computer Vision Engineer (Internship)</td>\n",
       "      <td>Fluendo</td>\n",
       "      <td>Barcelona</td>\n",
       "      <td>Hace 1 mes</td>\n",
       "      <td>https://es.linkedin.com/jobs/view/computer-vis...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>Middle Data Analyst - Python (Incorporación en...</td>\n",
       "      <td>Teralco Group</td>\n",
       "      <td>Barcelona</td>\n",
       "      <td>Hace 3 días</td>\n",
       "      <td>https://es.linkedin.com/jobs/view/middle-data-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>Data Engineer</td>\n",
       "      <td>Experfy</td>\n",
       "      <td>Barcelona</td>\n",
       "      <td>Hace 1 mes</td>\n",
       "      <td>https://es.linkedin.com/jobs/view/data-enginee...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>Data Scientist (m/f/d)</td>\n",
       "      <td>Linde</td>\n",
       "      <td>Barcelona</td>\n",
       "      <td>Hace 1 mes</td>\n",
       "      <td>https://es.linkedin.com/jobs/view/data-scienti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Wallapop</td>\n",
       "      <td>Barcelona</td>\n",
       "      <td>Hace 1 mes</td>\n",
       "      <td>https://es.linkedin.com/jobs/view/data-scienti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>Data Product Line Owner</td>\n",
       "      <td>Experfy</td>\n",
       "      <td>Barcelona</td>\n",
       "      <td>Hace 1 mes</td>\n",
       "      <td>https://es.linkedin.com/jobs/view/data-product...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                title  \\\n",
       "0              Tècnic/a Suport Direcció Ref. 107-2023   \n",
       "1                                      Data Scientist   \n",
       "2                          Data Visualization Analyst   \n",
       "3                                        Data Analyst   \n",
       "4   Research Assistant in the Department of Economics   \n",
       "5                                        Data Analyst   \n",
       "6   Graduado/a para dar apoyo en un proyecto de in...   \n",
       "7   Research Assistant in Data Science/Management/...   \n",
       "8                        Business Analytics (Flights)   \n",
       "9                                      Data Scientist   \n",
       "10                                     Data Scientist   \n",
       "11                           Data Analyst - QA Tester   \n",
       "12                          Junior Analytics Engineer   \n",
       "13                                       Data Analyst   \n",
       "14             Industrial Affairs (IA) Data Scientist   \n",
       "15  Research Assistant in Economics/Marketing/Finance   \n",
       "16                                     Data Scientist   \n",
       "17                                     DATA SCIENTIST   \n",
       "18  Full-time research assistant position Prof. Vi...   \n",
       "19  Junior Product Analyst (Full remote within Spain)   \n",
       "20                              Data Scientist Junior   \n",
       "21                                     Data Scientist   \n",
       "22                                     Data Scientist   \n",
       "23             Data Scientist - Bioinformática Remoto   \n",
       "24      Data Scientist - Bioinformática - 100% remoto   \n",
       "25              Research Assistant Prof. Hester Zhang   \n",
       "26  PERSONAL AMB TITULACIÓ SUPERIOR EN PSICOLOGIA ...   \n",
       "27                        Becario/a Analista de Datos   \n",
       "28                     BECARIO/A DATA ANALYST CLIENTE   \n",
       "29                           Principal Data Scientist   \n",
       "30        Data Science - 100% remoto (based in Spain)   \n",
       "31                                   Business Analyst   \n",
       "32                            Data Analyst Internship   \n",
       "33                            Data Management Officer   \n",
       "34                                     Data Scientist   \n",
       "35                            REPORTING & CONTROLLING   \n",
       "36                                   Business Analyst   \n",
       "37                 Python Developer Jr. (for ML team)   \n",
       "38                                     DATA SCIENTIST   \n",
       "39      Junior Sales Development Representative (SDR)   \n",
       "40  Investigador/a Inteligencia Artificial Optimiz...   \n",
       "41                                Lead Data Scientist   \n",
       "42                         Market Intelligence Intern   \n",
       "43                            Chief Operating Officer   \n",
       "44              Computer Vision Engineer (Internship)   \n",
       "45  Middle Data Analyst - Python (Incorporación en...   \n",
       "46                                      Data Engineer   \n",
       "47                             Data Scientist (m/f/d)   \n",
       "48                                     Data Scientist   \n",
       "49                            Data Product Line Owner   \n",
       "\n",
       "                                         company                  location  \\\n",
       "0            Hospital Sant Joan de Déu Barcelona    Esplugues de Llobregat   \n",
       "1                                        Hubtype                 Barcelona   \n",
       "2                                        Experfy                 Barcelona   \n",
       "3                                          Coniq                 Barcelona   \n",
       "4   IESE Business School - University of Navarra                 Barcelona   \n",
       "5                                       Exoticca                 Barcelona   \n",
       "6           Fundació de Recerca Sant Joan de Déu     Sant Boi de Llobregat   \n",
       "7   IESE Business School - University of Navarra                 Barcelona   \n",
       "8                                       Exoticca                 Barcelona   \n",
       "9                             Paper Street Media                 Barcelona   \n",
       "10                            Paper Street Media                 Barcelona   \n",
       "11                                       Experfy                 Barcelona   \n",
       "12                                      Exoticca                 Barcelona   \n",
       "13                          Birchman Group Spain                 Barcelona   \n",
       "14                                       Experfy                 Barcelona   \n",
       "15  IESE Business School - University of Navarra                 Barcelona   \n",
       "16                                        Smadex                 Barcelona   \n",
       "17                                         MANGO                 Barcelona   \n",
       "18  IESE Business School - University of Navarra                 Barcelona   \n",
       "19                                Leadtech Group                 Barcelona   \n",
       "20                            Between Technology  Palau-solità i Plegamans   \n",
       "21                                       Winning                 Barcelona   \n",
       "22     Eurecat - Centro Tecnológico de Catalunya                 Barcelona   \n",
       "23                                Page Personnel                 Barcelona   \n",
       "24                                Page Personnel   Barcelona y alrededores   \n",
       "25  IESE Business School - University of Navarra                 Barcelona   \n",
       "26          Fundació de Recerca Sant Joan de Déu     Sant Boi de Llobregat   \n",
       "27                                 Grupo Planeta                 Barcelona   \n",
       "28                                         MANGO                 Barcelona   \n",
       "29                                       Experfy                 Barcelona   \n",
       "30                                  Michael Page                 Barcelona   \n",
       "31                            Paper Street Media                 Barcelona   \n",
       "32                                            HP     Sant Cugat del Vallès   \n",
       "33                           HOLA CONSULTORES SL                 Barcelona   \n",
       "34                                Page Personnel                 Barcelona   \n",
       "35                                         MANGO                 Barcelona   \n",
       "36                            Paper Street Media                 Barcelona   \n",
       "37                                        Smadex                 Barcelona   \n",
       "38                                         MANGO                 Barcelona   \n",
       "39                                       Hubtype                 Barcelona   \n",
       "40     Eurecat - Centro Tecnológico de Catalunya                 Barcelona   \n",
       "41                                       Experfy                 Barcelona   \n",
       "42                                          Mars                 Barcelona   \n",
       "43                                      ABCDx SA                 Barcelona   \n",
       "44                                       Fluendo                 Barcelona   \n",
       "45                                 Teralco Group                 Barcelona   \n",
       "46                                       Experfy                 Barcelona   \n",
       "47                                         Linde                 Barcelona   \n",
       "48                                      Wallapop                 Barcelona   \n",
       "49                                       Experfy                 Barcelona   \n",
       "\n",
       "              time                                                url  \n",
       "0    Hace 1 semana  https://es.linkedin.com/jobs/view/t%C3%A8cnic-...  \n",
       "1       Hace 1 mes  https://es.linkedin.com/jobs/view/data-scienti...  \n",
       "2     Hace 3 meses  https://es.linkedin.com/jobs/view/data-visuali...  \n",
       "3       Hace 1 mes  https://es.linkedin.com/jobs/view/data-analyst...  \n",
       "4    Hace 1 semana  https://es.linkedin.com/jobs/view/research-ass...  \n",
       "5     Hace 2 meses  https://es.linkedin.com/jobs/view/data-analyst...  \n",
       "6   Hace 2 semanas  https://es.linkedin.com/jobs/view/graduado-a-p...  \n",
       "7    Hace 1 semana  https://es.linkedin.com/jobs/view/research-ass...  \n",
       "8     Hace 2 meses  https://es.linkedin.com/jobs/view/business-ana...  \n",
       "9    Hace 11 horas  https://es.linkedin.com/jobs/view/data-scienti...  \n",
       "10      Hace 1 mes  https://es.linkedin.com/jobs/view/data-scienti...  \n",
       "11      Hace 1 mes  https://es.linkedin.com/jobs/view/data-analyst...  \n",
       "12  Hace 3 semanas  https://es.linkedin.com/jobs/view/junior-analy...  \n",
       "13    Hace 2 meses  https://es.linkedin.com/jobs/view/data-analyst...  \n",
       "14    Hace 3 meses  https://es.linkedin.com/jobs/view/industrial-a...  \n",
       "15     Hace 4 días  https://es.linkedin.com/jobs/view/research-ass...  \n",
       "16      Hace 1 mes  https://es.linkedin.com/jobs/view/data-scienti...  \n",
       "17    Hace 7 horas  https://es.linkedin.com/jobs/view/data-scienti...  \n",
       "18      Hace 1 mes  https://es.linkedin.com/jobs/view/full-time-re...  \n",
       "19    Hace 3 meses  https://es.linkedin.com/jobs/view/junior-produ...  \n",
       "20    Hace 2 meses  https://es.linkedin.com/jobs/view/data-scienti...  \n",
       "21      Hace 1 mes  https://es.linkedin.com/jobs/view/data-scienti...  \n",
       "22      Hace 1 mes  https://es.linkedin.com/jobs/view/data-scienti...  \n",
       "23      Hace 1 día  https://es.linkedin.com/jobs/view/data-scienti...  \n",
       "24     Hace 4 días  https://es.linkedin.com/jobs/view/data-scienti...  \n",
       "25  Hace 2 semanas  https://es.linkedin.com/jobs/view/research-ass...  \n",
       "26  Hace 3 semanas  https://es.linkedin.com/jobs/view/personal-amb...  \n",
       "27  Hace 2 semanas  https://es.linkedin.com/jobs/view/becario-a-an...  \n",
       "28      Hace 1 mes  https://es.linkedin.com/jobs/view/becario-a-da...  \n",
       "29    Hace 3 meses  https://es.linkedin.com/jobs/view/principal-da...  \n",
       "30     Hace 5 días  https://es.linkedin.com/jobs/view/data-science...  \n",
       "31   Hace 11 horas  https://es.linkedin.com/jobs/view/business-ana...  \n",
       "32      Hace 1 mes  https://es.linkedin.com/jobs/view/data-analyst...  \n",
       "33     Hace 3 días  https://es.linkedin.com/jobs/view/data-managem...  \n",
       "34     Hace 4 días  https://es.linkedin.com/jobs/view/data-scienti...  \n",
       "35  Hace 3 semanas  https://es.linkedin.com/jobs/view/reporting-co...  \n",
       "36      Hace 1 mes  https://es.linkedin.com/jobs/view/business-ana...  \n",
       "37      Hace 1 mes  https://es.linkedin.com/jobs/view/python-devel...  \n",
       "38      Hace 1 mes  https://es.linkedin.com/jobs/view/data-scienti...  \n",
       "39   Hace 1 semana  https://es.linkedin.com/jobs/view/junior-sales...  \n",
       "40    Hace 2 meses  https://es.linkedin.com/jobs/view/investigador...  \n",
       "41    Hace 3 meses  https://es.linkedin.com/jobs/view/lead-data-sc...  \n",
       "42    Hace 3 horas  https://es.linkedin.com/jobs/view/market-intel...  \n",
       "43      Hace 1 mes  https://es.linkedin.com/jobs/view/chief-operat...  \n",
       "44      Hace 1 mes  https://es.linkedin.com/jobs/view/computer-vis...  \n",
       "45     Hace 3 días  https://es.linkedin.com/jobs/view/middle-data-...  \n",
       "46      Hace 1 mes  https://es.linkedin.com/jobs/view/data-enginee...  \n",
       "47      Hace 1 mes  https://es.linkedin.com/jobs/view/data-scienti...  \n",
       "48      Hace 1 mes  https://es.linkedin.com/jobs/view/data-scienti...  \n",
       "49      Hace 1 mes  https://es.linkedin.com/jobs/view/data-product...  "
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "import os\n",
    "import pandas as pd\n",
    "import time\n",
    "import random\n",
    "import getpass\n",
    "from bs4 import BeautifulSoup\n",
    "from tqdm import tqdm\n",
    "from urllib.parse import urlencode\n",
    "from urllib.parse import quote\n",
    "\n",
    "from selenium import webdriver\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "from selenium.common.exceptions import NoSuchElementException, StaleElementReferenceException\n",
    "\n",
    "\n",
    "\n",
    "def scraping_cards_on_the_left (job_title=\"data\", location=\"Barcelona, Catalonia, Spain\"):\n",
    "\n",
    "    # 1. Initializing driver\n",
    "    options = webdriver.ChromeOptions()\n",
    "    options.binary_location = '/Applications/Google Chrome.app/Contents/MacOS/Google Chrome'\n",
    "    wd = webdriver.Chrome(options=options)\n",
    "    \n",
    "    # 2. Building the string\n",
    "\n",
    "    url = enconding_url (job_title, location, base_url)\n",
    "    \n",
    "    \n",
    "    #3 . Get the data\n",
    "    wd.get(url)\n",
    "    no_of_jobs = int(wd.find_element(By.CSS_SELECTOR, \"h1>span\").get_attribute('innerText'))\n",
    "    print(\"no_of_jobs: \", no_of_jobs)\n",
    "    wd.find_element(By.CSS_SELECTOR, '.jobs-search__results-list')\n",
    "    \n",
    "    jobsitos = []\n",
    "    els_jobs = []\n",
    "\n",
    "    i = 119\n",
    "\n",
    "    while i <= int(no_of_jobs/25) + 1:\n",
    "        wd.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "        i = i + 1\n",
    "        try:\n",
    "            job_lists = wd.find_element(By.CSS_SELECTOR, '.jobs-search__results-list')\n",
    "            listita = job_lists.get_attribute('outerHTML')\n",
    "            soup = BeautifulSoup(listita, \"html.parser\")\n",
    "            soup_2 = soup.find_all(\"ul\", {\"class\": \"jobs-search__results-list\"})\n",
    "\n",
    "            # 1. EXTRAER JOB A JOB\n",
    "            for pagina in soup_2:\n",
    "                jobsitos.append(pagina)\n",
    "            #print(\"Jobsitos: \", jobsitos)\n",
    "\n",
    "\n",
    "            # 2. EXTRAER LA INFO DE CADA JOB\n",
    "            for job in jobsitos:\n",
    "                job_list = job.find_all(\"li\")\n",
    "\n",
    "                for the_one_job in job_list:\n",
    "                    url = the_one_job.find_all(\"a\")[0].get(\"href\")\n",
    "                    title = the_one_job.find_all(\"span\", {\"class\":\"sr-only\"})[0].text.strip()\n",
    "                    location = the_one_job.find_all(\"span\", {\"class\": \"job-search-card__location\" })[0].text.strip()\n",
    "                    company = the_one_job.find_all(\"h4\")[0].find(\"a\").text.strip()\n",
    "                    the_time = the_one_job.find_all(\"time\")[0].text.strip()\n",
    "\n",
    "\n",
    "                    dict_ = {\n",
    "                        \"title\": title,\n",
    "                        \"company\": company,\n",
    "                        \"location\": location,\n",
    "                        \"time\": the_time,\n",
    "                        \"url\": url,\n",
    "\n",
    "                    }\n",
    "                    \n",
    "                    if dict_ not in els_jobs:\n",
    "                        els_jobs.append(dict_)\n",
    "\n",
    "            time.sleep(5)\n",
    "\n",
    "        except:\n",
    "            pass\n",
    "        time.sleep(5)\n",
    "\n",
    "    os.system(\"say -v Monica don escreipin\")\n",
    "    return pd.DataFrame(els_jobs)\n",
    "\n",
    "df_2 = scraping_cards_on_the_left ()\n",
    "df_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "465aca17",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b10f7288",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('all_data_analysts_jobs175.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54ce6a7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_loaded = pd.read_csv(\"primer_exito_bro_to_wapo.csv\")\n",
    "#df_loaded.drop(columns=\"Unnamed: 0\", inplace=True)\n",
    "df_loaded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df6acd16",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_loaded = pd.read_csv('all_data_analysts_jobs175.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c09204fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_loaded.url[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dc36fdf",
   "metadata": {},
   "source": [
    "# Scrapear detalles del job"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec6c5e31",
   "metadata": {},
   "source": [
    "options = webdriver.ChromeOptions()\n",
    "options.binary_location = '/Applications/Google Chrome.app/Contents/MacOS/Google Chrome'\n",
    "wd = webdriver.Chrome(options=options)\n",
    "url_job = \"https://es.linkedin.com/jobs/view/data-analyst-at-coniq-3652827423?refId=LmHLqc2XCC2YJGeJ%2BOJlfw%3D%3D&trackingId=CtHhJ%2Fe3ZQTxs8KZpryElw%3D%3D&position=1&pageNum=0&trk=public_jobs_jserp-result_search-card\"\n",
    "wd.get(url_job)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "577e5211",
   "metadata": {},
   "source": [
    "#Description’: jd\n",
    "#Seniority\n",
    "#Type’: emp_type,\n",
    "#Function’: job_func,"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50b5336c",
   "metadata": {},
   "source": [
    "def logging_in (url):\n",
    "    \n",
    "    # 1. Initializing driver\n",
    "    options = webdriver.ChromeOptions()\n",
    "    options.binary_location = '/Applications/Google Chrome.app/Contents/MacOS/Google Chrome'\n",
    "    wd = webdriver.Chrome(options=options)\n",
    "    wd.get(url)\n",
    "    \n",
    "    # 2. Try to log-in\n",
    "    \n",
    "    try:\n",
    "        time.sleep(5)\n",
    "        driver.find_element(By.XPATH,'/html/body/header/nav/div/a[2]').click()\n",
    "        mail = 'cocazapata.21@gmail.com'\n",
    "        pw = 'fcbarcelona21'\n",
    "        time.sleep(3)\n",
    "        print(\"Logging in\")\n",
    "\n",
    "        username = wait.until(EC.visibility_of_element_located((By.ID, 'username'))).send_keys(mail)\n",
    "        password = wait.until(EC.visibility_of_element_located((By.ID, 'password'))).send_keys(pw)\n",
    "        password.send_keys(Keys.RETURN)\n",
    "        time.sleep(2)\n",
    "        return wd.page_source\n",
    "        \n",
    "    # 3. Otherwise: try to just get the content\n",
    "        \n",
    "    except:\n",
    "        print(\"Not logging in\")\n",
    "        time.sleep(2)\n",
    "        return wd.page_source"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a86cd438",
   "metadata": {},
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "\n",
    "def info_un_job(url):\n",
    "    \n",
    "    response = logging_in (url)\n",
    "    soup = BeautifulSoup(response, 'html.parser')\n",
    "    descripcion = soup.find('div', {\"class\":'description__text description__text--rich'}).get_text(strip=True)\n",
    "    nivel_antiguedad = soup.find('span', {\"class\":\"description__job-criteria-text description__job-criteria-text--criteria\"}).get_text(strip=True)\n",
    "    sectores = soup.find('span', {\"class\":\"description__job-criteria-text description__job-criteria-text--criteria\"})\n",
    "    \n",
    "    dict_ = {\n",
    "        \"description\": descripcion,\n",
    "        \"nivel_antiguedad\": nivel_antiguedad,\n",
    "        \"sectores\": sectores\n",
    "    }\n",
    "    \n",
    "    return dict_\n",
    "    \n",
    "\n",
    "url = 'https://es.linkedin.com/jobs/view/data-analyst-at-coniq-3652827423?refId=LmHLqc2XCC2YJGeJ%2BOJlfw%3D%3D&trackingId=CtHhJ%2Fe3ZQTxs8KZpryElw%3D%3D&position=1&pageNum=0&trk=public_jobs_jserp-result_search-card'\n",
    "\n",
    "resultado = info_un_job(url)\n",
    "resultado\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9c41a3d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "984eea2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The version of chrome cannot be detected. Trying with latest driver version\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging in\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "If using all scalar values, you must pass an index",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/q7/v3v0dp3x75b1z141v2hlcr3c0000gn/T/ipykernel_85548/1270443523.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[0murl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'https://es.linkedin.com/jobs/view/data-analyst-at-coniq-3652827423?refId=LmHLqc2XCC2YJGeJ%2BOJlfw%3D%3D&trackingId=CtHhJ%2Fe3ZQTxs8KZpryElw%3D%3D&position=1&pageNum=0&trk=public_jobs_jserp-result_search-card'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[0mresultado\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minfo_un_job\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 78\u001b[0;31m \u001b[0mdf_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresultado\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     79\u001b[0m \u001b[0mdf_test\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[1;32m    634\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    635\u001b[0m             \u001b[0;31m# GH#38939 de facto copy defaults to False only in non-dict cases\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 636\u001b[0;31m             \u001b[0mmgr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict_to_mgr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtyp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmanager\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    637\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMaskedArray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    638\u001b[0m             \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmrecords\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mmrecords\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/core/internals/construction.py\u001b[0m in \u001b[0;36mdict_to_mgr\u001b[0;34m(data, index, columns, dtype, typ, copy)\u001b[0m\n\u001b[1;32m    500\u001b[0m         \u001b[0;31m# TODO: can we get rid of the dt64tz special case above?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    501\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 502\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0marrays_to_mgr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtyp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtyp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconsolidate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    503\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    504\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/core/internals/construction.py\u001b[0m in \u001b[0;36marrays_to_mgr\u001b[0;34m(arrays, columns, index, dtype, verify_integrity, typ, consolidate)\u001b[0m\n\u001b[1;32m    118\u001b[0m         \u001b[0;31m# figure out the index, if necessary\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mindex\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 120\u001b[0;31m             \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_extract_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    121\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m             \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mensure_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/pandas/core/internals/construction.py\u001b[0m in \u001b[0;36m_extract_index\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m    662\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    663\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mindexes\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mraw_lengths\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 664\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"If using all scalar values, you must pass an index\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    665\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    666\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mhave_series\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: If using all scalar values, you must pass an index"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from bs4 import BeautifulSoup\n",
    "from datetime import datetime\n",
    "\n",
    "def logging_in(url):\n",
    "    options = webdriver.ChromeOptions()\n",
    "    options.binary_location = '/Applications/Google Chrome.app/Contents/MacOS/Google Chrome'\n",
    "    wd = webdriver.Chrome(options=options)\n",
    "    wd.get(url)\n",
    "\n",
    "    try:\n",
    "        time.sleep(5)\n",
    "        wd.find_element(By.XPATH, '/html/body/header/nav/div/a[2]').click()\n",
    "        mail = 'cocazapata.21@gmail.com'\n",
    "        pw = 'fcbarcelona21'\n",
    "        time.sleep(3)\n",
    "        print(\"Logging in\")\n",
    "\n",
    "        username = wd.find_element(By.ID, 'username')\n",
    "        username.send_keys(mail)\n",
    "        password = wd.find_element(By.ID, 'password')\n",
    "        password.send_keys(pw)\n",
    "        password.send_keys(Keys.RETURN)\n",
    "        time.sleep(2)\n",
    "        return wd\n",
    "    except:\n",
    "        print(\"Not logging in\")\n",
    "        time.sleep(2)\n",
    "        return wd\n",
    "\n",
    "def info_un_job(url):\n",
    "    \n",
    "    wd = logging_in(url)\n",
    "    \n",
    "    response = wd.page_source\n",
    "    soup = BeautifulSoup(response, 'html.parser')\n",
    "    \n",
    "    company = soup.find('span', {\"class\":\"jobs-unified-top-card__company-name\"}).get_text(strip=True)\n",
    "    position = soup.find('h1', {\"class\":\"t-24 t-bold jobs-unified-top-card__job-title\"}).get_text(strip=True)\n",
    "    location = soup.find('span', {\"class\":\"jobs-unified-top-card__bullet\"}).get_text(strip=True)\n",
    "    workplace = soup.find('span', {\"class\":\"jobs-unified-top-card__workplace-type\"}).get_text(strip=True)\n",
    "    type_and_level = soup.find(\"li\", {\"class\": \"jobs-unified-top-card__job-insight\"}).find(\"span\").text.strip()\n",
    "    description = soup.find('div', {\"class\": 'jobs-box__html-content jobs-description-content__text t-14 t-normal jobs-description-content__text--stretch'}).get_text(strip=True)\n",
    "    date = soup.find('span', {\"class\":\"jobs-unified-top-card__posted-date\"}).get_text(strip=True)\n",
    "    today = datetime.today().strftime('%d-%m-%Y')\n",
    "    n_alumnis = soup.find('a', {\"class\":'app-aware-link'}).get_text(strip=True)\n",
    "    applicants = soup.find('span', {\"class\": 'jobs-unified-top-card__applicant-count'}).get_text(strip=True).split(\" \")[0]\n",
    "    workers = soup.find(\"li\", {\"class\":\"jobs-unified-top-card__job-insight\"}).get(\"span\")\n",
    "    enllaç = soup.find(\"span\", {\"class\":\"jobs-unified-top-card__company-name\"}).get(\"href\")\n",
    "\n",
    "    # SKILLS\n",
    "   \n",
    "    dict_2 = {\n",
    "        \"company\" : company,\n",
    "        \"position\": position,\n",
    "        \"location\": location,\n",
    "        \"workplace\" : workplace,\n",
    "        \"description\": description,\n",
    "        \"type_and_level\": type_and_level,\n",
    "        \"date\": date,\n",
    "        \"today\": today,\n",
    "        \"n_alumnis\": n_alumnis,\n",
    "        \"applicants\": applicants,\n",
    "        \"url\": url,\n",
    "        \"workers\" : workers,\n",
    "        \"enllaç\": enllaç\n",
    "    }\n",
    "    \n",
    "    os.system(\"say -v Monica don escreipin\")\n",
    "\n",
    "    return dict_2\n",
    "\n",
    "url = 'https://es.linkedin.com/jobs/view/data-analyst-at-coniq-3652827423?refId=LmHLqc2XCC2YJGeJ%2BOJlfw%3D%3D&trackingId=CtHhJ%2Fe3ZQTxs8KZpryElw%3D%3D&position=1&pageNum=0&trk=public_jobs_jserp-result_search-card'\n",
    "resultado = info_un_job(url)\n",
    "df_test = pd.DataFrame(resultado)\n",
    "df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "beb59394",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'company': 'Coniq',\n",
       " 'position': 'Data Analyst',\n",
       " 'location': 'Barcelona, Catalonia, Spain',\n",
       " 'workplace': 'On-site',\n",
       " 'description': 'About the jobConiq is a dynamic, high growth UK-based SaaS company that provides total customer engagement and loyalty services to many of the world’s leading property developers, shopping centers and retailers. Coniq powers well over £1 billion of sales annually for its clients, with more than 20 million consumers shopping at 1,800 brands in 24 countries worldwide, and has offices in Europe, the US and the Middle East.Coniq is looking for a Data Analst to join our brilliant team in Barcelona. We have a robust data infrastructure and we need someone to help us develop our industry-leading product offerings and capabilities to the next level. If you’re looking for a position which will offer variety, complexity, responsibility and challenges, this could be the role for you and we’d love to start a conversation!ResponsibilitiesDevelop the roadmap for our client facing reporting and dashboardsInteract with the internal client success teamCommunicate with clients to understand complex requirementsInterpret data, analyze results using statistical techniques and provide ongoing reportsAcquire data from primary or secondary data sources and maintain databases/data systemsIdentify, analyze, and interpret trends or patterns in complex data setsFilter and “clean” data by reviewing computer reports, printouts, and performance indicators to locate and correct code problemsWork with management to prioritize business and information needsRequirementsYou should be comfortable working in a multi-disciplinary, agile team. You are used to designing reports, analysing data, developing insights, implementing best practice and participating in group design sessions. You have experience of designing and implementing reporting dashboards and are able to pick up on key discussion points for communication with stakeholders. You can operate as a data and reporting expert with internal and external stakeholders.These are the skills you will be able to bring to the Coniq team:2-5 years’ experience as a data analystAt least 2 years experience with SQL and relational databases (MySQL knowledge a bonus)Experience with a data visualisation tool a mustComfortable working with data across a range of sources, shapes and sizes, and you are confident turning this into quality informationInterest in engaging with colleagues to define reporting requirements from clients and interallyInterest in proactively looking at data to pull out insights which can be fed back to clients or internallyAbility to stay on top of current business and industry trends around data prep and visualisation technologiesEffectively use Tableau and related technologies to deliver quality analytics and data insight to our clientsStrong communicator, with the ability to work across the different business teams to understand requirements and deliverPython knowledge a bonusExperience with Tableau a bonusExperience with Sisense a bonusInterest in growing into a team management roleRelevant university degree a bonusBenefitsWe offer a generous package, including:Competitive salaryCompany stock options25 days holiday plus statutory holidaysA day off to celebrate your birthdayA day off for your wellbeingShorter working hours on FridaysA strong company values framework, including paid leave for volunteering with approved charitiesRegular team building activitiesTraining & development allowanceNew employee referral schemeThis is a unique opportunity to join a VC-funded high growth SaaS business where we all share a passion to work together to build a great product and a great company. We are proud of our company culture and invest a great deal into making sure that we promote Diversity in the workplace. Together we come from over 20 nationalities and as a tech business, we are very proud of 50/50 gender split.',\n",
       " 'type_and_level': 'Full-time · Associate',\n",
       " 'date': '1 month ago',\n",
       " 'today': '10-07-2023',\n",
       " 'n_alumnis': '',\n",
       " 'applicants': <span class=\"jobs-unified-top-card__applicant-count\">\n",
       "                       87 applicants\n",
       "                     </span>,\n",
       " 'url': 'https://es.linkedin.com/jobs/view/data-analyst-at-coniq-3652827423?refId=LmHLqc2XCC2YJGeJ%2BOJlfw%3D%3D&trackingId=CtHhJ%2Fe3ZQTxs8KZpryElw%3D%3D&position=1&pageNum=0&trk=public_jobs_jserp-result_search-card',\n",
       " 'workers': None,\n",
       " 'enllaç': None}"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resultado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6c67cdc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4fb57ae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2851b228",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "081ac35e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e070e997",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "3dff63f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "resultado = info_un_job(\"https://www.linkedin.com/jobs/view/3647687937/?alternateChannel=search&refId=zJ444F2EhVjX43eyXSKCCg%3D%3D&trackingId=isOlTSiDs2x5SVr3SQs6HQ%3D%3D\", wd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b335bf8f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1883c368",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df_2 = pd.DataFrame([resultado])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dd4788c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2.to_csv(\"data_inside_one_job_toda_info.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c52a057",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0fd6510",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "# Assuming \"all_data_analysts_jobs\" is the dataframe containing the URLs\n",
    "all_data_analysts_jobs =pd.read_csv('all_data_analysts_jobs.csv') # Replace ... with your actual dataframe creation code\n",
    "\n",
    "# Create an empty dataframe to store the extracted information\n",
    "extracted_data = pd.DataFrame(columns=[\"company\", \"position\", \"location\", \"workplace\", \"description\", \"type_and_level\", \"date\"])\n",
    "\n",
    "# Iterate over each URL in the dataframe\n",
    "for index, row in all_data_analysts_jobs.iterrows():\n",
    "    url = row['url']\n",
    "    wd = logging_in(url)\n",
    "    resultado = info_un_job(url, wd)\n",
    "    \n",
    "    # Append the extracted information to the dataframe\n",
    "    extracted_data = extracted_data.append(resultado, ignore_index=True)\n",
    "    \n",
    "    # Add a delay of 5 seconds between each iteration\n",
    "    time.sleep(5)\n",
    "\n",
    "# Save the extracted data to a new dataframe or a file\n",
    "extracted_data.to_csv(\"extracted_data.csv\", index=False)  # Example: Save as CSV file\n",
    "# extracted_data.to_excel(\"extracted_data.xlsx\", index=False)  # Example: Save as Excel file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c4aa1de",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6bc4138",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dbfabb2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18e7e945",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cf1b43b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "82826992",
   "metadata": {},
   "source": [
    "jobsasos = []\n",
    "\n",
    "for item in range(len(jobs)):\n",
    "\n",
    "    # Haciendo clic en el trabajo para ver los detalles del trabajo\n",
    "    job_click_path = f'/html/body/main/div/section[2]/ul/li[{item+1}]/img'\n",
    "    job_click = jobs[item].find_element_by_xpath(job_click_path).click()\n",
    "    time.sleep(5)\n",
    "\n",
    "    jd_path = '/html/body/main/section/div[2]/section[2]/div'\n",
    "    jd = wd.find_element_by_xpath(jd_path).get_attribute('innerText')\n",
    "    jd.append(jd)\n",
    "\n",
    "    seniority_path = '/html/body/main/section/div[2]/section[2]/ul/li[1]/span'\n",
    "    seniority = wd.find_element_by_xpath(seniority_path).get_attribute('innerText')\n",
    "    seniority.append(seniority)\n",
    "\n",
    "    emp_type_path = '/html/body/main/section/div[2]/section[2]/ul/li[2]/span'\n",
    "    emp_type = wd.find_element_by_xpath(emp_type_path).get_attribute('innerText')\n",
    "    emp_type.append(emp_type)\n",
    "\n",
    "    job_func_path = '/html/body/main/section/div[2]/section[2]/ul/li[3]/span'\n",
    "    job_func_elements = wd.find_elements_by_xpath(job_func_path)\n",
    "    for element in job_func_elements:\n",
    "        job_func.append(element.get_attribute('innerText'))\n",
    "    job_func_final = ', '.join(job_func)\n",
    "    job_func.append(job_func_final)\n",
    "\n",
    "    industries_path = '/html/body/main/section/div[2]/section[2]/ul/li[4]/span'\n",
    "    industries_elements = wd.find_elements_by_xpath(industries_path)\n",
    "    for element in industries_elements:\n",
    "        industries.append(element.get_attribute('innerText'))\n",
    "    industries_final = ', '.join(industries)\n",
    "    #industries.append(industries_final)\n",
    "\n",
    "   \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4efee4ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "job_data = pd.DataFrame({\n",
    "    'ID': job_id,\n",
    "    'Date': date,\n",
    "    'Company': company_name,\n",
    "    'Title': job_title,\n",
    "    'Location': location,\n",
    "    'Description': jd,\n",
    "    'Level': seniority,\n",
    "    'Type': emp_type,\n",
    "    'Function': job_func,\n",
    "    'Industry': industries,\n",
    "    'Link': job_link\n",
    "})\n",
    "\n",
    "# Limpiar la columna \"Description\"\n",
    "job_data['Description'] = job_data['Description'].str.replace('\\n', ' ')\n",
    "\n",
    "job_data.to_excel('LinkedIn Job Data_Data Scientist.xlsx', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "371bf394",
   "metadata": {},
   "outputs": [],
   "source": [
    "job_data = pd.DataFrame({‘ID’: job_id,\n",
    "‘Date’: date,\n",
    "‘Company’: company_name,\n",
    "‘Title’: job_title,\n",
    "‘Location’: location,\n",
    "'Description’: jd,\n",
    "‘Level’: seniority,\n",
    "‘Type’: emp_type,\n",
    "‘Function’: job_func,\n",
    "‘Industry’: industries,\n",
    "‘Link’: job_link\n",
    "})\n",
    "# cleaning description column\n",
    "job_data[‘Description’] = job_data[‘Description’].str.replace(‘\\n’,’ ‘)\n",
    "job_data.to_excel('LinkedIn Job Data_Data Scientist.xlsx', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ecde766",
   "metadata": {},
   "source": [
    "```python\n",
    "# Data management\n",
    "import pandas as pd\n",
    "import string\n",
    "\n",
    "# Databases\n",
    "import sqlalchemy as alch\n",
    "from getpass import getpass\n",
    "from pymongo import MongoClient\n",
    "\n",
    "from IPython.display import Image\n",
    "\n",
    "\n",
    "# Languages\n",
    "import re\n",
    "\n",
    "import spacy\n",
    "#import es_core_news_sm\n",
    "\n",
    "import nltk\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "from wordcloud import WordCloud\n",
    "from langdetect import detect\n",
    "from textblob import TextBlob\n",
    "\n",
    "from nltk import WordNetLemmatizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "text = [\"I love writing code in Python. I love Python code\",\n",
    "        \"I hate writing code in Java. I hate Java code\"]\n",
    "\n",
    "\n",
    "df = pd.DataFrame({'review': ['review1', 'review2'], 'text':text})\n",
    "\n",
    "\n",
    "cv = CountVectorizer(stop_words='english')\n",
    "cv_matrix = cv.fit_transform(df['text'])\n",
    "df_dtm = pd.DataFrame(cv_matrix.toarray(),\n",
    "                      index=df['review'].values,\n",
    "                      columns=cv.get_feature_names())\n",
    "df_dtm\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
